{"cells":[{"cell_type":"markdown","metadata":{"id":"Tq3u5wyrWj-8"},"source":["Based on \n","* https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb\n","* https://www.sbert.net/docs/usage/semantic_textual_similarity.html\n","\n","\n","---\n","\n","\n","\n","Embedding - key for efficient transfer learning that widely used last times. Sentence Embedding allow to encode texts of any length to vectors that will contains a lot of information for future works. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1075,"status":"ok","timestamp":1682085298724,"user":{"displayName":"Mikhail Salnikov","userId":"03220482591013244005"},"user_tz":-180},"id":"BBgqoautsgOn","outputId":"a9fe350d-02b5-4abd-e89c-dc33945a73ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fri Apr 21 13:54:57 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   72C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6047,"status":"ok","timestamp":1682085305114,"user":{"displayName":"Mikhail Salnikov","userId":"03220482591013244005"},"user_tz":-180},"id":"b7RO5lXIUpID","outputId":"4c0aea58-53fb-4cc9-ed83-edf36ffe823c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.9/dist-packages (2.2.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.11.0)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.9/dist-packages (4.28.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.10.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (3.8.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (0.15.1+cu118)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (0.13.4)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (2.0.0+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.22.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (4.65.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (0.1.98)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.4.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (3.11.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (2022.10.31)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (0.13.3)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers) (1.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers) (8.1.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->sentence-transformers) (8.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n"]}],"source":["pip install -U sentence-transformers datasets transformers[torch]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lwOkxet3XtKZ"},"outputs":[],"source":["from sentence_transformers import SentenceTransformer, util\n","\n","# Two lists of sentences\n","sentences1 = [\n","    'The cat sits outside',\n","    'A man is playing guitar',\n","    'The new movie is awesome',\n","    'Новый фильм очень крутой',\n","    'Этот текст описывает современное искусство',\n","  ]\n","\n","sentences2 = [\n","    'The dog plays in the garden',\n","    'A woman watches TV',\n","    'The new movie is so great',\n","    'The new movie is so cool',\n","    'Lets talk about language agnostic sentence encoding like LaBSE',\n","]\n","\n","def evaluate_model(model, sentences1, sentences2):\n","  #Compute embedding for both lists\n","  embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n","  embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n","\n","  #Compute cosine-similarities\n","  cosine_scores = util.cos_sim(embeddings1, embeddings2)\n","\n","  #Output the pairs with their score\n","  for i in range(len(sentences1)):\n","      print(f\"{sentences1[i]:50} {sentences2[i]:70} Score: {cosine_scores[i][i]:.4f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"cQFpfY33iZnz"},"source":["BERT trained only on English, it's ok, but how can we solve multilangiage problem? "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3919,"status":"ok","timestamp":1682085312708,"user":{"displayName":"Mikhail Salnikov","userId":"03220482591013244005"},"user_tz":-180},"id":"capsyov-Yukz","outputId":"1b936569-e637-4dc8-eff8-8e3ffe13c65b"},"outputs":[{"name":"stdout","output_type":"stream","text":["The cat sits outside                               The dog plays in the garden                                            Score: 0.2733\n","A man is playing guitar                            A woman watches TV                                                     Score: -0.0123\n","The new movie is awesome                           The new movie is so great                                              Score: 0.8913\n","Новый фильм очень крутой                           The new movie is so cool                                               Score: -0.0158\n","Этот текст описывает современное искусство         Lets talk about language agnostic sentence encoding like LaBSE         Score: 0.0137\n"]}],"source":["evaluate_model(\n","    SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2'),\n","    sentences1,\n","    sentences2,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10651,"status":"ok","timestamp":1682085323353,"user":{"displayName":"Mikhail Salnikov","userId":"03220482591013244005"},"user_tz":-180},"id":"KtzQJKK8f9Ko","outputId":"257f1f5f-775f-4fe1-edb8-a29761f7c6e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["The cat sits outside                               The dog plays in the garden                                            Score: 0.6546\n","A man is playing guitar                            A woman watches TV                                                     Score: 0.4668\n","The new movie is awesome                           The new movie is so great                                              Score: 0.9434\n","Новый фильм очень крутой                           The new movie is so cool                                               Score: 0.9086\n","Этот текст описывает современное искусство         Lets talk about language agnostic sentence encoding like LaBSE         Score: 0.1525\n"]}],"source":["evaluate_model(\n","    SentenceTransformer('sentence-transformers/LaBSE'),\n","    sentences1,\n","    sentences2,\n",")"]},{"cell_type":"markdown","metadata":{"id":"-P8WUHoZkQBr"},"source":["# Question Answering"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NbS2MTopgBme"},"outputs":[],"source":["from datasets import load_dataset, load_metric\n","from datasets import ClassLabel, Sequence\n","import random\n","import pandas as pd\n","from IPython.display import display, HTML\n","\n","from transformers import AutoTokenizer\n","import transformers\n","from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n","\n","\n","model_checkpoint = \"sentence-transformers/all-MiniLM-L6-v2\"\n","batch_size = 16"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236,"referenced_widgets":["91bf0e0b769c465297e8cd0912e6c370","7230fcf579f74910bd17329b34032272","85d2b4fb42974380860b1b78b2aff3bb","8f2362e7b58947ce99d72b194a0b2a43","5fe84fff9e2a4e2081850766e19623f2","9bab9975b5d8426f8fe0d217d63cb6ba","a7f661564160451f92b34de0810c5d9b","015e4faa032a45a2a8f19cbd9a491932","7671f45100d44d6694b96c8baea42367","cccdd614ffd64a0ca4614dec8b18c675","fff6400058c44933ace21e7bcd8756e8"]},"executionInfo":{"elapsed":1045,"status":"ok","timestamp":1682085330935,"user":{"displayName":"Mikhail Salnikov","userId":"03220482591013244005"},"user_tz":-180},"id":"xSh0zehKkWfw","outputId":"7e77ab5b-c5a4-42c1-b9a1-46e6865a3f1f"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.builder:Found cached dataset squad_v2 (/root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"91bf0e0b769c465297e8cd0912e6c370","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 130319\n","    })\n","    validation: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 11873\n","    })\n","})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["dataset = load_dataset(\"squad_v2\")\n","dataset"]},{"cell_type":"markdown","metadata":{"id":"dGc7xPNKkplC"},"source":["We can see the training, validation and test sets all have a column for the context, the question and the answers to those questions."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1682085330936,"user":{"displayName":"Mikhail Salnikov","userId":"03220482591013244005"},"user_tz":-180},"id":"xDaCJkeYkk0a","outputId":"cad7d2ec-5a0d-483d-b2ae-a0b8d6cfede1"},"outputs":[{"data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>answers</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5a1f6f6654a786001a36b2bd</td>\n","      <td>Videoconferencing</td>\n","      <td>VRS services have become well developed nationally in Sweden since 1997 and also in the United States since the first decade of the 2000s. With the exception of Sweden, VRS has been provided in Europe for only a few years since the mid-2000s, and as of 2010 has not been made available in many European Union countries, with most European countries still lacking the legislation or the financing for large-scale VRS services, and to provide the necessary telecommunication equipment to deaf users. Germany and the Nordic countries are among the other leaders in Europe, while the United States is another world leader in the provisioning of VRS services.</td>\n","      <td>What has become developed in Germany since 1997?</td>\n","      <td>{'text': [], 'answer_start': []}</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>572f7d6f04bcaa1900d76a19</td>\n","      <td>Hyderabad</td>\n","      <td>Hyderabad has a tropical wet and dry climate (Köppen Aw) bordering on a hot semi-arid climate (Köppen BSh). The annual mean temperature is 26.6 °C (79.9 °F); monthly mean temperatures are 21–33 °C (70–91 °F). Summers (March–June) are hot and humid, with average highs in the mid-to-high 30s Celsius; maximum temperatures often exceed 40 °C (104 °F) between April and June. The coolest temperatures occur in December and January, when the lowest temperature occasionally dips to 10 °C (50 °F). May is the hottest month, when daily temperatures range from 26 to 39 °C (79–102 °F); December, the coldest, has temperatures varying from 14.5 to 28 °C (57–82 °F).</td>\n","      <td>What is the mean yearly temperature in Hyderabad in Celsius?</td>\n","      <td>{'text': ['26.6 °C'], 'answer_start': [139]}</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5728dbd84b864d1900164fab</td>\n","      <td>Paris</td>\n","      <td>According to Eurostat, the EU statistical agency, in 2012 the Commune of Paris was the most densely populated city in the European Union, with 21,616 people per square kilometre within the city limits (the NUTS-3 statistical area), ahead of Inner London West, which had 10,374 people per square kilometre. According to the same census, three departments bordering Paris, Hauts-de-Seine, Seine-Saint-Denis and Val-de-Marne, had population densities of over ten thousand people per square kilometre, ranking among the ten most densely populated areas of the EU.</td>\n","      <td>How many people lived per square kilometer in the city limits?</td>\n","      <td>{'text': ['21,616'], 'answer_start': [143]}</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>56f83111aef2371900625ed9</td>\n","      <td>Szlachta</td>\n","      <td>For many centuries, wealthy and powerful members of the szlachta sought to gain legal privileges over their peers. Few szlachta were wealthy enough to be known as magnates (karmazyni—the \"Crimsons\", from the crimson colour of their boots). A proper magnate should be able to trace noble ancestors back for many generations and own at least 20 villages or estates. He should also hold a major office in the Commonwealth.</td>\n","      <td>What did powerful leaders of szlachta sought?</td>\n","      <td>{'text': ['gain legal privileges over their peers'], 'answer_start': [75]}</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5733eb23d058e614000b65c6</td>\n","      <td>Premier_League</td>\n","      <td>The Football Association Premier League Ltd (FAPL) is operated as a corporation and is owned by the 20 member clubs. Each club is a shareholder, with one vote each on issues such as rule changes and contracts. The clubs elect a chairman, chief executive, and board of directors to oversee the daily operations of the league. The current chairman is Sir Dave Richards, who was appointed in April 1999, and the chief executive is Richard Scudamore, appointed in November 1999. The former chairman and chief executive, John Quinton and Peter Leaver, were forced to resign in March 1999 after awarding consultancy contracts to former Sky executives Sam Chisholm and David Chance. The Football Association is not directly involved in the day-to-day operations of the Premier League, but has veto power as a special shareholder during the election of the chairman and chief executive and when new rules are adopted by the league.</td>\n","      <td>Who is the current CEO of the Premier League?</td>\n","      <td>{'text': ['Richard Scudamore'], 'answer_start': [428]}</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5731d073b9d445190005e58c</td>\n","      <td>Separation_of_church_and_state_in_the_United_States</td>\n","      <td>In 2002, a three judge panel on the Ninth Circuit Court of Appeals held that classroom recitation of the Pledge of Allegiance in a California public school was unconstitutional, even when students were not compelled to recite it, due to the inclusion of the phrase \"under God.\" In reaction to the case, Elk Grove Unified School District v. Newdow, both houses of Congress passed measures reaffirming their support for the pledge, and condemning the panel's ruling. The case was appealed to the Supreme Court, where the case was ultimately overturned in June 2004, solely on procedural grounds not related to the substantive constitutional issue. Rather, a five-justice majority held that Newdow, a non-custodial parent suing on behalf of his daughter, lacked standing to sue.</td>\n","      <td>Why was the case of Elk Grove Unified School District v. Newdow overturned?</td>\n","      <td>{'text': ['procedural grounds'], 'answer_start': [574]}</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>5ad3a0e1604f3c001a3fe9bf</td>\n","      <td>Separation_of_powers_under_the_United_States_Constitution</td>\n","      <td>Many political scientists believe that separation of powers is a decisive factor in what they see as a limited degree of American exceptionalism. In particular, John W. Kingdon made this argument, claiming that separation of powers contributed to the development of a unique political structure in the United States. He attributes the unusually large number of interest groups active in the United States, in part, to the separation of powers; it gives groups more places to try to influence, and creates more potential group activity. He also cites its complexity as one of the reasons for lower citizen participation.[citation needed]</td>\n","      <td>What do many political scientists attribute the large number of active interest groups in the US to?</td>\n","      <td>{'text': [], 'answer_start': []}</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>572751d2dd62a815002e9afa</td>\n","      <td>Cotton</td>\n","      <td>GM cotton acreage in India grew at a rapid rate, increasing from 50,000 hectares in 2002 to 10.6 million hectares in 2011. The total cotton area in India was 12.1 million hectares in 2011, so GM cotton was grown on 88% of the cotton area. This made India the country with the largest area of GM cotton in the world. A long-term study on the economic impacts of Bt cotton in India, published in the Journal PNAS in 2012, showed that Bt cotton has increased yields, profits, and living standards of smallholder farmers. The U.S. GM cotton crop was 4.0 million hectares in 2011 the second largest area in the world, the Chinese GM cotton crop was third largest by area with 3.9 million hectares and Pakistan had the fourth largest GM cotton crop area of 2.6 million hectares in 2011. The initial introduction of GM cotton proved to be a success in Australia – the yields were equivalent to the non-transgenic varieties and the crop used much less pesticide to produce (85% reduction). The subsequent introduction of a second variety of GM cotton led to increases in GM cotton production until 95% of the Australian cotton crop was GM in 2009 making Australia the country with the fifth largest GM cotton crop in the world. Other GM cotton growing countries in 2011 were Argentina, Myanmar, Burkina Faso, Brazil, Mexico, Colombia, South Africa and Costa Rica.</td>\n","      <td>How much area was planted in India in GM cotton in 2011?</td>\n","      <td>{'text': ['10.6 million hectares'], 'answer_start': [92]}</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>5a7e47de70df9f001a875678</td>\n","      <td>Cork_(city)</td>\n","      <td>The city's charter was granted by Prince John, as Lord of Ireland, in 1185. The city was once fully walled, and some wall sections and gates remain today. For much of the Middle Ages, Cork city was an outpost of Old English culture in the midst of a predominantly hostile Gaelic countryside and cut off from the English government in the Pale around Dublin. Neighbouring Gaelic and Hiberno-Norman lords extorted \"Black Rent\" from the citizens to keep them from attacking the city. The present extent of the city has exceeded the medieval boundaries of the Barony of Cork City; it now takes in much of the neighbouring Barony of Cork. Together, these baronies are located between the Barony of Barrymore to the east, Muskerry East to the west and Kerrycurrihy to the south.</td>\n","      <td>Who granted the Barony of Barrymore's charter?</td>\n","      <td>{'text': [], 'answer_start': []}</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>5ad11eda645df0001a2d0e41</td>\n","      <td>Uranium</td>\n","      <td>It is estimated that 5.5 million tonnes of uranium exists in ore reserves that are economically viable at US$59 per lb of uranium, while 35 million tonnes are classed as mineral resources (reasonable prospects for eventual economic extraction). Prices went from about $10/lb in May 2003 to $138/lb in July 2007. This has caused a big increase in spending on exploration, with US$200 million being spent worldwide in 2005, a 54% increase on the previous year. This trend continued through 2006, when expenditure on exploration rocketed to over $774 million, an increase of over 250% compared to 2004. The OECD Nuclear Energy Agency said exploration figures for 2007 would likely match those for 2006.</td>\n","      <td>In 2015, how much money was spent on uranium exploration?</td>\n","      <td>{'text': [], 'answer_start': []}</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["def show_random_elements(dataset, num_examples=10):\n","    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n","    picks = []\n","    for _ in range(num_examples):\n","        pick = random.randint(0, len(dataset)-1)\n","        while pick in picks:\n","            pick = random.randint(0, len(dataset)-1)\n","        picks.append(pick)\n","    \n","    df = pd.DataFrame(dataset[picks])\n","    for column, typ in dataset.features.items():\n","        if isinstance(typ, ClassLabel):\n","            df[column] = df[column].transform(lambda i: typ.names[i])\n","        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n","            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n","    display(HTML(df.to_html()))\n","\n","show_random_elements(dataset[\"train\"])"]},{"cell_type":"markdown","metadata":{"id":"MqJcB14zlMko"},"source":["## Preprocessing\n","\n","We instantiate our tokenizer with the AutoTokenizer.from_pretrained method, which will ensure:\n","\n","we get a tokenizer that corresponds to the model architecture we want to use,\n","we download the vocabulary used when pretraining this specific checkpoint.\n","That vocabulary will be cached, so it's not downloaded again the next time we run the cell."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e7s33Kusk0Ji"},"outputs":[],"source":["max_length = 384 # The maximum length of a feature (question and context)\n","doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed.\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"]},{"cell_type":"markdown","metadata":{"id":"xRIMMkN-nKu1"},"source":["One specific thing for the preprocessing in question answering is how to deal with very long documents. We usually truncate them in other tasks, when they are longer than the model maximum sentence length, but here, removing part of the the context might result in losing the answer we are looking for. To deal with this, we will allow one (long) example in our dataset to give several input features, each of length shorter than the maximum length of the model (or the one we set as a hyper-parameter). Also, just in case the answer lies at the point we split a long context, we allow some overlap between the features we generate controlled by the hyper-parameter `doc_stride`:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":330,"status":"ok","timestamp":1682085331508,"user":{"displayName":"Mikhail Salnikov","userId":"03220482591013244005"},"user_tz":-180},"id":"gYYQvE2wnNk7","outputId":"76fc42ca-e8f8-4183-ba68-320125d1fb7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Without any truncation, we get the following length for the input IDs: 437\n","Now, if we just truncate, we will lose information (and possibly the answer to our question): 384\n"]}],"source":["for i, example in enumerate(dataset[\"train\"]):\n","    if len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"]) > max_length:\n","        break\n","example = dataset[\"train\"][i]\n","\n","print(\n","    \"Without any truncation, we get the following length for the input IDs:\",\n","    len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"])\n",")\n","\n","print(\n","    \"Now, if we just truncate, we will lose information (and possibly the answer to our question):\",\n","    len(tokenizer(example[\"question\"], example[\"context\"], max_length=max_length, truncation=\"only_second\")[\"input_ids\"])\n",")"]},{"cell_type":"markdown","metadata":{"id":"btgrafbNmkdJ"},"source":["Note that we never want to truncate the question, only the context, else the only_second truncation picked. Now, our tokenizer can automatically return us a list of features capped by a certain maximum length, with the overlap we talked above, we just have to tell it with `return_overflowing_tokens=True` and by passing the stride:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1682085331509,"user":{"displayName":"Mikhail Salnikov","userId":"03220482591013244005"},"user_tz":-180},"id":"cWuAq-7smod2","outputId":"743dbcb4-16bd-4f0e-fc65-1f6bb91e643d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Now we don't have one list of input_ids, but several: [384, 192]\n"]}],"source":["tokenized_example = tokenizer(\n","    example[\"question\"],\n","    example[\"context\"],\n","    max_length=max_length,\n","    truncation=\"only_second\",\n","    return_overflowing_tokens=True,\n","    stride=doc_stride\n",")\n","\n","\n","print(\n","    \"Now we don't have one list of input_ids, but several:\",\n","    [len(x) for x in tokenized_example[\"input_ids\"]]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1682085331509,"user":{"displayName":"Mikhail Salnikov","userId":"03220482591013244005"},"user_tz":-180},"id":"W17AB-pUnvVT","outputId":"5103d2ac-5b1e-4958-fef0-fe40411fb1b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["[CLS] beyonce got married in 2008 to whom? [SEP] on april 4, 2008, beyonce married jay z. she publicly revealed their marriage in a video montage at the listening party for her third studio album, i am... sasha fierce, in manhattan's sony club on october 22, 2008. i am... sasha fierce was released on november 18, 2008 in the united states. the album formally introduces beyonce's alter ego sasha fierce, conceived during the making of her 2003 single \" crazy in love \", selling 482, 000 copies in its first week, debuting atop the billboard 200, and giving beyonce her third consecutive number - one album in the us. the album featured the number - one song \" single ladies ( put a ring on it ) \" and the top - five songs \" if i were a boy \" and \" halo \". achieving the accomplishment of becoming her longest - running hot 100 single in her career, \" halo \"'s success in the us helped beyonce attain more top - ten singles on the list than any other woman during the 2000s. it also included the successful \" sweet dreams \", and singles \" diva \", \" ego \", \" broken - hearted girl \" and \" video phone \". the music video for \" single ladies \" has been parodied and imitated around the world, spawning the \" first major dance craze \" of the internet age according to the toronto star. the video has won several awards, including best video at the 2009 mtv europe music awards, the 2009 scottish mobo awards, and the 2009 bet awards. at the 2009 mtv video music awards, the video was nominated for nine awards, ultimately winning three including video of the year. its failure to win the best female video category, which went to american country pop singer taylor swift's \" you belong with me \", led to kanye west interrupting the ceremony and beyonce [SEP]\n","[CLS] beyonce got married in 2008 to whom? [SEP] single ladies \" has been parodied and imitated around the world, spawning the \" first major dance craze \" of the internet age according to the toronto star. the video has won several awards, including best video at the 2009 mtv europe music awards, the 2009 scottish mobo awards, and the 2009 bet awards. at the 2009 mtv video music awards, the video was nominated for nine awards, ultimately winning three including video of the year. its failure to win the best female video category, which went to american country pop singer taylor swift's \" you belong with me \", led to kanye west interrupting the ceremony and beyonce improvising a re - presentation of swift's award during her own acceptance speech. in march 2009, beyonce embarked on the i am... world tour, her second headlining worldwide concert tour, consisting of 108 shows, grossing $ 119. 5 million. [SEP]\n"]}],"source":["for x in tokenized_example[\"input_ids\"][:2]:\n","    print(tokenizer.decode(x))"]},{"cell_type":"markdown","metadata":{"id":"4HKRUTDRn_K3"},"source":["Now this will give us some work to properly treat the answers: we need to find in which of those features the answer actually is, and where exactly in that feature. The models we will use require the start and end positions of these answers in the tokens, so we will also need to to map parts of the original context to some tokens. Thankfully, the tokenizer we're using can help us with that by returning an `offset_mapping`:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1682085331509,"user":{"displayName":"Mikhail Salnikov","userId":"03220482591013244005"},"user_tz":-180},"id":"vcXFRUUzn-7w","outputId":"c0df5da6-f655-4f51-c66d-e0c6d8e40cd4"},"outputs":[{"name":"stdout","output_type":"stream","text":["[(0, 0), (0, 7), (8, 11), (12, 19), (20, 22), (23, 27), (28, 30), (31, 35), (35, 36), (0, 0), (0, 2), (3, 8), (9, 10), (10, 11), (12, 16), (16, 17), (18, 25), (26, 33), (34, 37), (38, 39)]\n"]}],"source":["tokenized_example = tokenizer(\n","    example[\"question\"],\n","    example[\"context\"],\n","    max_length=max_length,\n","    truncation=\"only_second\",\n","    return_overflowing_tokens=True,\n","    return_offsets_mapping=True,\n","    stride=doc_stride\n",")\n","print(tokenized_example[\"offset_mapping\"][0][:20])"]},{"cell_type":"markdown","metadata":{"id":"d3pTlCvEoRum"},"source":["This gives, for each index of our input IDS, the corresponding start and end character in the original text that gave our token. The very first token ([CLS]) has (0, 0) because it doesn't correspond to any part of the question/answer, then the second token is the same as the characters 0 to 3 of the question:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1682085331509,"user":{"displayName":"Mikhail Salnikov","userId":"03220482591013244005"},"user_tz":-180},"id":"kg2YCWPNooBq","outputId":"f72d8590-eb8f-4588-f266-d6a5e851c865"},"outputs":[{"name":"stdout","output_type":"stream","text":["beyonce Beyonce\n"]}],"source":["first_token_id = tokenized_example[\"input_ids\"][0][1]\n","offsets = tokenized_example[\"offset_mapping\"][0][1]\n","print(tokenizer.convert_ids_to_tokens([first_token_id])[0], example[\"question\"][offsets[0]:offsets[1]])"]},{"cell_type":"markdown","metadata":{"id":"-ReRjmAhowuw"},"source":["So we can use this mapping to find the position of the start and end tokens of our answer in a given feature. We just have to distinguish which parts of the offsets correspond to the question and which part correspond to the context, this is where the `sequence_ids` method of our `tokenized_example` can be useful:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1682085331509,"user":{"displayName":"Mikhail Salnikov","userId":"03220482591013244005"},"user_tz":-180},"id":"TwUMS8ziowN5","outputId":"205dd145-6f21-4252-f9cf-aa8ff038f18b"},"outputs":[{"name":"stdout","output_type":"stream","text":["[None, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"]}],"source":["sequence_ids = tokenized_example.sequence_ids()\n","print(sequence_ids)"]},{"cell_type":"markdown","metadata":{"id":"c8rHiLVhpE-i"},"source":["It returns None for the special tokens, then 0 or 1 depending on whether the corresponding token comes from the first sentence past (the question) or the second (the context). Now with all of this, we can find the first and last token of the answer in one of our input feature (or if the answer is not in this feature):"]},{"cell_type":"markdown","metadata":{"id":"gySblI2MpWdt"},"source":["Now let's put everything together in one function we will apply to our training set. In the case of impossible answers (the answer is in another feature given by an example with a long context), we set the cls index for both the start and end position. We could also simply discard those examples from the training set if the flag `allow_impossible_answers` is False. Since the preprocessing is already complex enough as it is, we've kept is simple for this part."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wAwhL_u0lxk6"},"outputs":[],"source":["def prepare_train_features(examples):\n","    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n","    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n","    # left whitespace\n","    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n","\n","    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n","    # in one example possible giving several features when a context is long, each of those features having a\n","    # context that overlaps a bit the context of the previous feature.\n","    tokenized_examples = tokenizer(\n","        examples[\"question\"],\n","        examples[\"context\"],\n","        truncation=\"only_second\",\n","        max_length=max_length,\n","        stride=doc_stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    # Since one example might give us several features if it has a long context, we need a map from a feature to\n","    # its corresponding example. This key gives us just that.\n","    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n","    # The offset mappings will give us a map from token to character position in the original context. This will\n","    # help us compute the start_positions and end_positions.\n","    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n","\n","    # Let's label those examples!\n","    tokenized_examples[\"start_positions\"] = []\n","    tokenized_examples[\"end_positions\"] = []\n","\n","    for i, offsets in enumerate(offset_mapping):\n","        # We will label impossible answers with the index of the CLS token.\n","        input_ids = tokenized_examples[\"input_ids\"][i]\n","        cls_index = input_ids.index(tokenizer.cls_token_id)\n","\n","        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n","        sequence_ids = tokenized_examples.sequence_ids(i)\n","\n","        # One example can give several spans, this is the index of the example containing this span of text.\n","        sample_index = sample_mapping[i]\n","        answers = examples[\"answers\"][sample_index]\n","        # If no answers are given, set the cls_index as answer.\n","        if len(answers[\"answer_start\"]) == 0:\n","            tokenized_examples[\"start_positions\"].append(cls_index)\n","            tokenized_examples[\"end_positions\"].append(cls_index)\n","        else:\n","            # Start/end character index of the answer in the text.\n","            start_char = answers[\"answer_start\"][0]\n","            end_char = start_char + len(answers[\"text\"][0])\n","\n","            # Start token index of the current span in the text.\n","            token_start_index = 0\n","            while sequence_ids[token_start_index] != 1:\n","                token_start_index += 1\n","\n","            # End token index of the current span in the text.\n","            token_end_index = len(input_ids) - 1\n","            while sequence_ids[token_end_index] != 1:\n","                token_end_index -= 1\n","\n","            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n","            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n","                tokenized_examples[\"start_positions\"].append(cls_index)\n","                tokenized_examples[\"end_positions\"].append(cls_index)\n","            else:\n","                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n","                # Note: we could go after the last offset if the answer is the last word (edge case).\n","                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n","                    token_start_index += 1\n","                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n","                while offsets[token_end_index][1] >= end_char:\n","                    token_end_index -= 1\n","                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n","\n","    return tokenized_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1682085331510,"user":{"displayName":"Mikhail Salnikov","userId":"03220482591013244005"},"user_tz":-180},"id":"kKGOu-oZphkr","outputId":"f743fe47-073a-4291-ac59-2b8653a335b6"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d/cache-a3101514d3b737b5.arrow\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d/cache-11783aa4e292765a.arrow\n"]}],"source":["tokenized_datasets = dataset.map(prepare_train_features, batched=True, remove_columns=dataset[\"train\"].column_names)"]},{"cell_type":"markdown","metadata":{"id":"4hmWRLNDq3Ts"},"source":["### Fine-tuning the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":642,"status":"ok","timestamp":1682085674948,"user":{"displayName":"Mikhail Salnikov","userId":"03220482591013244005"},"user_tz":-180},"id":"sFG6bKFLpk7y","outputId":"19559ceb-0568-4e5a-8615-bfa6a9b7a76a"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1682085674948,"user":{"displayName":"Mikhail Salnikov","userId":"03220482591013244005"},"user_tz":-180},"id":"QRxsygBy21fz","outputId":"3fa87227-2ff1-4e78-e1ac-a68897b4bfdb"},"outputs":[{"data":{"text/plain":["BertForQuestionAnswering(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n","      (position_embeddings): Embedding(512, 384)\n","      (token_type_embeddings): Embedding(2, 384)\n","      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-5): 6 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=384, out_features=384, bias=True)\n","              (key): Linear(in_features=384, out_features=384, bias=True)\n","              (value): Linear(in_features=384, out_features=384, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=384, out_features=384, bias=True)\n","              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=384, out_features=1536, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=1536, out_features=384, bias=True)\n","            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (qa_outputs): Linear(in_features=384, out_features=2, bias=True)\n",")"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0rHtgl1pxkEM"},"outputs":[],"source":["for name, param in model.named_parameters():\n","  if 'qa_outputs' not in name:\n","    param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gu5CmHZ3DPcR"},"outputs":[],"source":["from torch.optim import AdamW\n","\n","optimizer = AdamW(model.parameters(), lr=1e-4)\n","lr_scheduler = transformers.get_scheduler(\n","    name=\"constant_with_warmup\",\n","    optimizer=optimizer,\n","    num_warmup_steps=500,\n","    num_training_steps=5000,\n",")"]},{"cell_type":"markdown","metadata":{"id":"h9LKr4fPH1Ng"},"source":["We will use Learning rate like on this image"]},{"cell_type":"markdown","metadata":{"id":"sjyaSWwAHztW"},"source":["![image.png](data:image/png;base64,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)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":106},"id":"cD16v7W6sRVM","outputId":"67457ca5-c500-4c2c-d74a-75ae98c8859d"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5000/5000 09:31, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>2500</td>\n","      <td>3.891800</td>\n","      <td>3.335956</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>3.902900</td>\n","      <td>3.320937</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=5000, training_loss=4.0526876953125, metrics={'train_runtime': 571.6921, 'train_samples_per_second': 139.935, 'train_steps_per_second': 8.746, 'total_flos': 1962698711040000.0, 'train_loss': 4.0526876953125, 'epoch': 0.61})"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["model_name = model_checkpoint.split(\"/\")[-1]\n","args = TrainingArguments(\n","    f\"{model_name}-finetuned-squad\",\n","    evaluation_strategy=\"steps\",\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    max_steps=7500,\n","    eval_steps=2500,\n",")\n","trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    tokenizer=tokenizer,\n","    optimizers=(optimizer, lr_scheduler)\n",")\n","\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"lD9_vSd82hwy"},"source":["### Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dj_YhXQ5sXIJ"},"outputs":[],"source":["import torch\n","\n","for batch in trainer.get_eval_dataloader():\n","    break\n","batch = {k: v.to(trainer.args.device) for k, v in batch.items()}\n","with torch.no_grad():\n","    output = trainer.model(**batch)\n","output.keys()"]},{"cell_type":"markdown","metadata":{"id":"wFbGyt0O2o1m"},"source":["The output of the model is a dict-like object that contains the loss (since we provided labels), the start and end logits. We won't need the loss for our predictions, let's have a look a the logits:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r0HAifGs2jJI"},"outputs":[],"source":["output.start_logits.shape, output.end_logits.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KeUa_ZNF2qon"},"outputs":[],"source":["output.start_logits.argmax(dim=-1), output.end_logits.argmax(dim=-1)"]},{"cell_type":"markdown","metadata":{"id":"-8GVJfjj7HUx"},"source":["This will work great in a lot of cases, but what if this prediction gives us something impossible: the start position could be greater than the end position, or point to a span of text in the question instead of the answer. In that case, we might want to look at the second best prediction to see if it gives a possible answer and select that instead.\n","\n","To classify our answers, we will use the score obtained by adding the start and end logits. We won't try to order all the possible answers and limit ourselves to with a hyper-parameter we call n_best_size. We'll pick the best indices in the start and end logits and gather all the answers this predicts. After checking if each one is valid, we will sort them by their score and keep the best one. Here is how we would do this on the first feature in the batch:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TjTR5id02s0c"},"outputs":[],"source":["import numpy as np\n","\n","\n","n_best_size = 20\n","\n","start_logits = output.start_logits[0].cpu().numpy()\n","end_logits = output.end_logits[0].cpu().numpy()\n","# Gather the indices the best start/end logits:\n","start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n","end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n","valid_answers = []\n","for start_index in start_indexes:\n","    for end_index in end_indexes:\n","        if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n","            valid_answers.append(\n","                {\n","                    \"score\": start_logits[start_index] + end_logits[end_index],\n","                    \"text\": \"\" # We need to find a way to get back the original substring corresponding to the answer in the context\n","                }\n","            )"]},{"cell_type":"markdown","metadata":{"id":"DPtlhS-QEs4s"},"source":["And then we can sort the valid_answers according to their score and only keep the best one. The only point left is how to check a given span is inside the context (and not the question) and how to get back the text inside. To do this, we need to add two things to our validation features:\n","\n","* the ID of the example that generated the feature (since each example can generate several features, as seen before);\n","* the offset mapping that will give us a map from token indices to character positions in the context.\n","\n","That's why we will re-process the validation set with the following function, slightly different from `prepare_train_features`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mZWGjZPuD6yt"},"outputs":[],"source":["def prepare_validation_features(examples):\n","    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n","    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n","    # left whitespace\n","    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n","\n","    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n","    # in one example possible giving several features when a context is long, each of those features having a\n","    # context that overlaps a bit the context of the previous feature.\n","    tokenized_examples = tokenizer(\n","        examples[\"question\"],\n","        examples[\"context\"],\n","        truncation=\"only_second\",\n","        max_length=max_length,\n","        stride=doc_stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    # Since one example might give us several features if it has a long context, we need a map from a feature to\n","    # its corresponding example. This key gives us just that.\n","    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n","\n","    # We keep the example_id that gave us this feature and we will store the offset mappings.\n","    tokenized_examples[\"example_id\"] = []\n","\n","    for i in range(len(tokenized_examples[\"input_ids\"])):\n","        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n","        sequence_ids = tokenized_examples.sequence_ids(i)\n","        context_index = 1\n","\n","        # One example can give several spans, this is the index of the example containing this span of text.\n","        sample_index = sample_mapping[i]\n","        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n","\n","        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n","        # position is part of the context or not.\n","        tokenized_examples[\"offset_mapping\"][i] = [\n","            (o if sequence_ids[k] == context_index else None)\n","            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n","        ]\n","\n","    return tokenized_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rr-pC-oYE5bF"},"outputs":[],"source":["validation_features = dataset[\"validation\"].map(\n","    prepare_validation_features,\n","    batched=True,\n","    remove_columns=dataset[\"validation\"].column_names\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"epytsJZwFavm"},"outputs":[],"source":["raw_predictions = trainer.predict(validation_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KEW-ZSvXFf1X"},"outputs":[],"source":["start_logits = output.start_logits[0].cpu().numpy()\n","end_logits = output.end_logits[0].cpu().numpy()\n","offset_mapping = validation_features[0][\"offset_mapping\"]\n","# The first feature comes from the first example. For the more general case, we will need to be match the example_id to\n","# an example index\n","context = dataset[\"validation\"][0][\"context\"]\n","\n","# Gather the indices the best start/end logits:\n","start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n","end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n","valid_answers = []\n","for start_index in start_indexes:\n","    for end_index in end_indexes:\n","        # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n","        # to part of the input_ids that are not in the context.\n","        if (\n","            start_index >= len(offset_mapping)\n","            or end_index >= len(offset_mapping)\n","            or offset_mapping[start_index] is None\n","            or offset_mapping[end_index] is None\n","        ):\n","            continue\n","        # Don't consider answers with a length that is either < 0 or > max_answer_length.\n","        if end_index < start_index or end_index - start_index + 1 > 30:\n","            continue\n","        if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n","            start_char = offset_mapping[start_index][0]\n","            end_char = offset_mapping[end_index][1]\n","            valid_answers.append(\n","                {\n","                    \"score\": start_logits[start_index] + end_logits[end_index],\n","                    \"text\": context[start_char: end_char]\n","                }\n","            )\n","\n","valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\n","valid_answers, dataset[\"validation\"][0][\"answers\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nUzlwfP3F7iS"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1B96U5ojrgqcqEwKtC35uXBG3DskwuH9h","timestamp":1682161015604}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"015e4faa032a45a2a8f19cbd9a491932":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fe84fff9e2a4e2081850766e19623f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7230fcf579f74910bd17329b34032272":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bab9975b5d8426f8fe0d217d63cb6ba","placeholder":"​","style":"IPY_MODEL_a7f661564160451f92b34de0810c5d9b","value":"100%"}},"7671f45100d44d6694b96c8baea42367":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85d2b4fb42974380860b1b78b2aff3bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_015e4faa032a45a2a8f19cbd9a491932","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7671f45100d44d6694b96c8baea42367","value":2}},"8f2362e7b58947ce99d72b194a0b2a43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cccdd614ffd64a0ca4614dec8b18c675","placeholder":"​","style":"IPY_MODEL_fff6400058c44933ace21e7bcd8756e8","value":" 2/2 [00:00&lt;00:00, 28.65it/s]"}},"91bf0e0b769c465297e8cd0912e6c370":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7230fcf579f74910bd17329b34032272","IPY_MODEL_85d2b4fb42974380860b1b78b2aff3bb","IPY_MODEL_8f2362e7b58947ce99d72b194a0b2a43"],"layout":"IPY_MODEL_5fe84fff9e2a4e2081850766e19623f2"}},"9bab9975b5d8426f8fe0d217d63cb6ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7f661564160451f92b34de0810c5d9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cccdd614ffd64a0ca4614dec8b18c675":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fff6400058c44933ace21e7bcd8756e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}